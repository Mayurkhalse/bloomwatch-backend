{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10fe1a52-1bd8-45a4-9161-cea0477f5bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ Authenticating Google Earth Engine...\n",
      "âœ… Earth Engine initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Bloom Prediction per-tile (LSTM + XGBoost Ensemble)\n",
    "# ------------------------------------------------------------\n",
    "# This notebook fetches data from Google Earth Engine per-tile,\n",
    "# prepares time-series, trains LSTM + XGBoost ensemble models,\n",
    "# and exports 1-year forecasts as JSON.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# CELL 1: Authenticate Google Earth Engine\n",
    "# ------------------------------------------------------------\n",
    "import os\n",
    "import ee\n",
    "\n",
    "try:\n",
    "    ee.Initialize()\n",
    "    print(\"âœ… Earth Engine already initialized.\")\n",
    "except Exception:\n",
    "    print(\"ğŸŒ Authenticating Google Earth Engine...\")\n",
    "    try:\n",
    "        ee.Authenticate(auth_mode='notebook')\n",
    "        ee.Initialize(project='kaksham-nasa-space-app')\n",
    "        print(\"âœ… Earth Engine initialized successfully.\")\n",
    "    except Exception as e2:\n",
    "        print(\"âŒ Earth Engine initialization failed:\", e2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "982e24d0-470d-447b-a07d-bb98d8fcd324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Created 10 tiles\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# CELL 2: Imports\n",
    "# ------------------------------------------------------------\n",
    "import json\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import geemap\n",
    "from shapely.geometry import box\n",
    "import geopandas as gpd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# CELL 3: Region and parameters\n",
    "# ------------------------------------------------------------\n",
    "lat_min, lon_min, lat_max, lon_max = -14.457555, 130.988109, -14.006022, 131.036692\n",
    "REGION = [lon_min, lat_min, lon_max, lat_max]\n",
    "START_DATE = '2019-01-01'\n",
    "END_DATE = datetime.date.today().isoformat()\n",
    "FORECAST_YEARS = 1\n",
    "TILE_SIZE_DEG = 0.05\n",
    "BLOOM_PROB_THRESHOLD = 0.6\n",
    "BLOOM_MODERATE_LOW = 0.3\n",
    "OUTPUT_JSON = '/content/bloom_predictions_per_tile.json'\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# CELL 4: Create tile grid\n",
    "# ------------------------------------------------------------\n",
    "def create_tiles(lon_min, lat_min, lon_max, lat_max, tile_size_deg=TILE_SIZE_DEG):\n",
    "    tiles = []\n",
    "    ix = 0\n",
    "    lon = lon_min\n",
    "    while lon < lon_max:\n",
    "        jx = 0\n",
    "        lat = lat_min\n",
    "        while lat < lat_max:\n",
    "            b = box(lon, lat, min(lon+tile_size_deg, lon_max), min(lat+tile_size_deg, lat_max))\n",
    "            tiles.append({\n",
    "                'tile_id': f'tile_{ix}_{jx}',\n",
    "                'geometry': b,\n",
    "                'lon_min': lon,\n",
    "                'lat_min': lat,\n",
    "                'lon_max': min(lon+tile_size_deg, lon_max),\n",
    "                'lat_max': min(lat+tile_size_deg, lat_max)\n",
    "            })\n",
    "            lat += tile_size_deg\n",
    "            jx += 1\n",
    "        lon += tile_size_deg\n",
    "        ix += 1\n",
    "    return gpd.GeoDataFrame(tiles)\n",
    "\n",
    "lon_min, lat_min, lon_max, lat_max = REGION\n",
    "tiles_gdf = create_tiles(lon_min, lat_min, lon_max, lat_max)\n",
    "print(f\"âœ… Created {len(tiles_gdf)} tiles\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84aa54c3-c9ab-4ed9-9450-971e6b445f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# CELL 5: Safe EE data extraction helpers\n",
    "# ------------------------------------------------------------\n",
    "def ee_time_series_to_df(collection_id, band, geom, start_date, end_date, scale=1000):\n",
    "    try:\n",
    "        col = ee.ImageCollection(collection_id).select(band).filterDate(start_date, end_date).filterBounds(geom)\n",
    "        def img_to_feature(img):\n",
    "            stat = img.reduceRegion(ee.Reducer.mean(), geom, scale=scale)\n",
    "            return ee.Feature(None, {'date': img.date().format('YYYY-MM-dd'), band: stat.get(band)})\n",
    "        fc = col.map(img_to_feature)\n",
    "        info = fc.getInfo()\n",
    "        if not info or 'features' not in info or len(info['features']) == 0:\n",
    "            print(f\"âš ï¸ No data for {band} in {collection_id}\")\n",
    "            return pd.DataFrame(columns=['date', band])\n",
    "        features = info['features']\n",
    "        rows = [{'date': f['properties']['date'], band: f['properties'].get(band, None)} for f in features]\n",
    "        df = pd.DataFrame(rows)\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df = df.sort_values('date').dropna()\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error fetching {band} from {collection_id}: {e}\")\n",
    "        return pd.DataFrame(columns=['date', band])\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# CELL 6: Per-tile extraction (fully corrected)\n",
    "# ------------------------------------------------------------\n",
    "def extract_features_for_tile(tile_row, start_date=START_DATE, end_date=END_DATE, scale=1000):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import ee\n",
    "\n",
    "    geom = ee.Geometry.Rectangle([tile_row.lon_min, tile_row.lat_min, tile_row.lon_max, tile_row.lat_max])\n",
    "    dfs = []\n",
    "\n",
    "    # MODIS vegetation indices\n",
    "    dfs.append(\n",
    "        ee_time_series_to_df('MODIS/061/MOD13A1', 'NDVI', geom, start_date, end_date, 250)\n",
    "        .rename(columns={'NDVI': 'ndvi'})\n",
    "    )\n",
    "    dfs.append(\n",
    "        ee_time_series_to_df('MODIS/061/MOD13A1', 'EVI', geom, start_date, end_date, 250)\n",
    "        .rename(columns={'EVI': 'evi'})\n",
    "    )\n",
    "\n",
    "    # MODIS land surface temperature\n",
    "    dfs.append(\n",
    "        ee_time_series_to_df('MODIS/061/MOD11A1', 'LST_Day_1km', geom, start_date, end_date, 1000)\n",
    "        .rename(columns={'LST_Day_1km': 'lst_day'})\n",
    "    )\n",
    "\n",
    "    # MODIS surface reflectance band 1\n",
    "    dfs.append(\n",
    "        ee_time_series_to_df('MODIS/061/MOD09GA', 'sur_refl_b01', geom, start_date, end_date, 500)\n",
    "    )\n",
    "\n",
    "    # CHIRPS precipitation\n",
    "    dfs.append(\n",
    "        ee_time_series_to_df('UCSB-CHG/CHIRPS/PENTAD', 'precipitation', geom, start_date, end_date, 5000)\n",
    "        .rename(columns={'precipitation': 'precip'})\n",
    "    )\n",
    "\n",
    "    # ECMWF ERA5-Land wind components\n",
    "    df_u = ee_time_series_to_df('ECMWF/ERA5_LAND/DAILY_AGGR', 'u_component_of_wind_10m', geom, start_date, end_date)\n",
    "    df_v = ee_time_series_to_df('ECMWF/ERA5_LAND/DAILY_AGGR', 'v_component_of_wind_10m', geom, start_date, end_date)\n",
    "    if not df_u.empty and not df_v.empty:\n",
    "        df_uv = pd.merge(df_u, df_v, on='date', how='outer')\n",
    "        df_uv['wind_speed'] = np.sqrt(df_uv.iloc[:, 1]**2 + df_uv.iloc[:, 2]**2)\n",
    "        dfs.append(df_uv[['date', 'wind_speed']])\n",
    "\n",
    "    # Merge all valid dataframes\n",
    "    valid_dfs = [d for d in dfs if not d.empty]\n",
    "    if len(valid_dfs) == 0:\n",
    "        print(f\"âš ï¸ No valid data found for {tile_row.tile_id}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = valid_dfs[0]\n",
    "    for d in valid_dfs[1:]:\n",
    "        df = pd.merge(df, d, on='date', how='outer')\n",
    "\n",
    "    # Interpolate and fill missing values using datetime index\n",
    "    df = df.sort_values('date')\n",
    "    df = df.set_index('date')\n",
    "    df = df.interpolate(method='time').ffill().bfill().dropna()\n",
    "    df = df.reset_index()  # Restore 'date' as a column\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47b8fcb2-f999-4349-85ec-e4fa9f954d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Processing tile_0_0...\n",
      "ğŸš€ Processing tile_0_1...\n",
      "ğŸš€ Processing tile_0_2...\n",
      "ğŸš€ Processing tile_0_3...\n",
      "ğŸš€ Processing tile_0_4...\n",
      "ğŸš€ Processing tile_0_5...\n",
      "ğŸš€ Processing tile_0_6...\n",
      "ğŸš€ Processing tile_0_7...\n",
      "ğŸš€ Processing tile_0_8...\n",
      "ğŸš€ Processing tile_0_9...\n",
      "âœ… Extracted data for 10 tiles.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# CELL 7: Extract for all tiles\n",
    "# ------------------------------------------------------------\n",
    "import os\n",
    "\n",
    "# Create a folder to store CSVs\n",
    "output_dir = \"tiles_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "all_tiles_data = {}\n",
    "for idx, row in tiles_gdf.iterrows():\n",
    "    print(f\"ğŸš€ Processing {row.tile_id}...\")\n",
    "    df_tile = extract_features_for_tile(row)\n",
    "    if df_tile.empty:\n",
    "        print(f\"âŒ No data extracted for {row.tile_id}\")\n",
    "        continue\n",
    "    all_tiles_data[row.tile_id] = df_tile\n",
    "    # Save CSV in the output folder\n",
    "    df_tile.to_csv(f\"{output_dir}/{row.tile_id}_timeseries.csv\", index=False)\n",
    "\n",
    "print(f\"âœ… Extracted data for {len(all_tiles_data)} tiles.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5c0d0ef-524d-4644-bfc1-1d5cb7e9bec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# CELL 8: Feature engineering & labeling\n",
    "# ------------------------------------------------------------\n",
    "def prepare_features(df, lookback=12):\n",
    "    df = df.copy().set_index('date').resample('M').mean()\n",
    "    df['ndvi_roll_mean_3'] = df.get('ndvi', pd.Series()).rolling(3).mean()\n",
    "    df['evi_roll_mean_3'] = df.get('evi', pd.Series()).rolling(3).mean()\n",
    "    df['precip_roll_sum_3'] = df.get('precip', pd.Series()).rolling(3).sum()\n",
    "    for lag in range(1, lookback+1):\n",
    "        for col in df.columns:\n",
    "            df[f'{col}_lag_{lag}'] = df[col].shift(lag)\n",
    "    return df.dropna()\n",
    "\n",
    "def create_labels_from_df(df_monthly):\n",
    "    labels = pd.Series(0, index=df_monthly.index)\n",
    "    if 'ndvi' in df_monthly.columns:\n",
    "        monthwise_q = df_monthly['ndvi'].groupby(df_monthly.index.month).quantile(0.9)\n",
    "        for d in df_monthly.index:\n",
    "            if df_monthly.loc[d,'ndvi'] > monthwise_q.loc[d.month]:\n",
    "                labels.loc[d] = 1\n",
    "    elif 'evi' in df_monthly.columns:\n",
    "        monthwise_q = df_monthly['evi'].groupby(df_monthly.index.month).quantile(0.9)\n",
    "        for d in df_monthly.index:\n",
    "            if df_monthly.loc[d,'evi'] > monthwise_q.loc[d.month]:\n",
    "                labels.loc[d] = 1\n",
    "    return labels\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# CELL 9: Model builders\n",
    "# ------------------------------------------------------------\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, input_shape=input_shape, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_xgb():\n",
    "    return XGBRegressor(objective='reg:squarederror', n_estimators=200, max_depth=4, learning_rate=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e91f23d-a6ef-4ecc-9141-58c763bc4e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Training for tile_0_0 ...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "ğŸ“˜ Training for tile_0_1 ...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step\n",
      "ğŸ“˜ Training for tile_0_2 ...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "ğŸ“˜ Training for tile_0_3 ...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "ğŸ“˜ Training for tile_0_4 ...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "ğŸ“˜ Training for tile_0_5 ...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "ğŸ“˜ Training for tile_0_6 ...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "ğŸ“˜ Training for tile_0_7 ...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "ğŸ“˜ Training for tile_0_8 ...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "ğŸ“˜ Training for tile_0_9 ...\n",
      "â© Not enough data for tile_0_9, skipping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# CELL 10: Train & forecast\n",
    "# ------------------------------------------------------------\n",
    "results = {}\n",
    "for tile_id, df in all_tiles_data.items():\n",
    "    print(f\"ğŸ“˜ Training for {tile_id} ...\")\n",
    "    df_feat = prepare_features(df, lookback=6)\n",
    "    if df_feat.shape[0] < 36:\n",
    "        print(f\"â© Not enough data for {tile_id}, skipping\")\n",
    "        continue\n",
    "    labels = create_labels_from_df(df_feat)\n",
    "    df_feat['label'] = labels\n",
    "    df_feat = df_feat.dropna()\n",
    "    X = df_feat.drop(columns=['label'])\n",
    "    y = df_feat['label']\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)\n",
    "    xgb = build_xgb()\n",
    "    xgb.fit(X_train, y_train)\n",
    "    xgb_pred_proba = xgb.predict(X_test)\n",
    "    timesteps = 3\n",
    "    def to_lstm_input(X_arr, timesteps=timesteps):\n",
    "        Xs = []\n",
    "        for i in range(timesteps, X_arr.shape[0]):\n",
    "            Xs.append(X_arr[i-timesteps:i, :])\n",
    "        return np.array(Xs)\n",
    "    Xs = to_lstm_input(X_scaled)\n",
    "    ys = y.values[timesteps:]\n",
    "    if Xs.shape[0] < 10:\n",
    "        print(f\"âš ï¸ Not enough points for LSTM on {tile_id}\")\n",
    "        lstm_proba = np.zeros_like(y_test)\n",
    "    else:\n",
    "        split_idx = int(0.8 * Xs.shape[0])\n",
    "        Xs_train, Xs_test = Xs[:split_idx], Xs[split_idx:]\n",
    "        ys_train, ys_test = ys[:split_idx], ys[split_idx:]\n",
    "        lstm = build_lstm_model((Xs_train.shape[1], Xs_train.shape[2]))\n",
    "        lstm.fit(Xs_train, ys_train, epochs=20, batch_size=8, verbose=0)\n",
    "        lstm_proba = lstm.predict(Xs_test).flatten()\n",
    "    min_len = min(len(xgb_pred_proba), len(lstm_proba)) if len(lstm_proba)>0 else len(xgb_pred_proba)\n",
    "    if min_len == 0:\n",
    "        ensemble_proba = xgb_pred_proba\n",
    "    else:\n",
    "        ensemble_proba = (xgb_pred_proba[-min_len:] + lstm_proba[-min_len:]) / 2.0\n",
    "    last_known = X_scaled[-timesteps:,:] if X_scaled.shape[0] >= timesteps else X_scaled\n",
    "    forecast_steps = FORECAST_YEARS * 12\n",
    "    forecasts = []\n",
    "    current_window = last_known.copy()\n",
    "    for step in range(forecast_steps):\n",
    "        xgb_feat = current_window[-1].reshape(1, -1)\n",
    "        p_xgb = xgb.predict(xgb_feat)[0]\n",
    "        try:\n",
    "            p_lstm = lstm.predict(current_window.reshape(1, current_window.shape[0], current_window.shape[1]))[0,0]\n",
    "        except Exception:\n",
    "            p_lstm = p_xgb\n",
    "        p_ens = float((p_xgb + p_lstm)/2.0)\n",
    "        severity = 'high' if p_ens > BLOOM_PROB_THRESHOLD else ('moderate' if p_ens >= BLOOM_MODERATE_LOW else 'low')\n",
    "        flag = 1 if p_ens > BLOOM_PROB_THRESHOLD else 0\n",
    "        last_date = df_feat.index.max()\n",
    "        forecast_date = (last_date + pd.DateOffset(months=step+1)).strftime('%Y-%m-%d')\n",
    "        forecasts.append({'date': forecast_date, 'probability': p_ens, 'severity': severity, 'flag': flag})\n",
    "        next_row = current_window[-1].copy()\n",
    "        current_window = np.vstack([current_window[1:], next_row]) if current_window.shape[0] > 1 else np.vstack([current_window, next_row])\n",
    "    results[tile_id] = {\n",
    "        'tile_id': tile_id,\n",
    "        'lon_min': float(tiles_gdf.loc[tiles_gdf['tile_id']==tile_id,'lon_min'].values[0]),\n",
    "        'lat_min': float(tiles_gdf.loc[tiles_gdf['tile_id']==tile_id,'lat_min'].values[0]),\n",
    "        'forecasts': forecasts\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e420872-e51f-49a1-84c7-86b44ebe5918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved forecasts to /content/bloom_predictions_per_tile.json\n",
      "Notebook run complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# CELL 11: Save output JSON\n",
    "# ------------------------------------------------------------\n",
    "with open(\"bloom_predictions_per_tile.json\", 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"âœ… Saved forecasts to {OUTPUT_JSON}\")\n",
    "print(\"Notebook run complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ea4b013-25f9-4401-8d72-3609fda53f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Generating NDVI and EVI predictions for next year...\n",
      "âœ… Added NDVI and EVI forecasts to each tile:\n",
      "  tile_0_0: NDVI=4743.512, EVI=2496.032\n",
      "  tile_0_1: NDVI=5026.675, EVI=2675.096\n",
      "  tile_0_2: NDVI=4307.433, EVI=2303.845\n",
      "  tile_0_3: NDVI=4055.981, EVI=2163.369\n",
      "  tile_0_4: NDVI=4065.472, EVI=2195.838\n",
      "  tile_0_5: NDVI=4399.152, EVI=2385.985\n",
      "  tile_0_6: NDVI=4523.016, EVI=2371.565\n",
      "  tile_0_7: NDVI=4453.367, EVI=2264.578\n",
      "  tile_0_8: NDVI=4697.954, EVI=2368.699\n",
      "ğŸ’¾ Saved updated predictions with NDVI and EVI.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# CELL 12: Predict NDVI and EVI for next year for each tile\n",
    "# ------------------------------------------------------------\n",
    "print(\"ğŸ”„ Generating NDVI and EVI predictions for next year...\")\n",
    "\n",
    "ndvi_evi_results = {}\n",
    "\n",
    "for tile_id, df in all_tiles_data.items():\n",
    "    if tile_id not in results:\n",
    "        continue  # skip tiles that weren't modeled\n",
    "\n",
    "    df_feat = prepare_features(df, lookback=6)\n",
    "    if df_feat.empty or 'ndvi' not in df_feat.columns or 'evi' not in df_feat.columns:\n",
    "        print(f\"âš ï¸ Skipping {tile_id} (missing NDVI/EVI data).\")\n",
    "        continue\n",
    "\n",
    "    # Use the most recent 12 months as input for NDVI and EVI trend prediction\n",
    "    df_recent = df_feat.iloc[-12:].copy()\n",
    "    if df_recent.empty:\n",
    "        continue\n",
    "\n",
    "    # Fit a simple XGB model for NDVI and EVI trends\n",
    "    xgb_ndvi = build_xgb()\n",
    "    xgb_evi = build_xgb()\n",
    "\n",
    "    X_ndvi = np.arange(len(df_recent)).reshape(-1, 1)\n",
    "    y_ndvi = df_recent['ndvi'].values\n",
    "    y_evi = df_recent['evi'].values\n",
    "\n",
    "    xgb_ndvi.fit(X_ndvi, y_ndvi)\n",
    "    xgb_evi.fit(X_ndvi, y_evi)\n",
    "\n",
    "    # Predict 12 months ahead (next year)\n",
    "    future_X = np.arange(len(df_recent), len(df_recent) + 12).reshape(-1, 1)\n",
    "    ndvi_pred = xgb_ndvi.predict(future_X)\n",
    "    evi_pred = xgb_evi.predict(future_X)\n",
    "\n",
    "    ndvi_next_year = float(np.mean(ndvi_pred))\n",
    "    evi_next_year = float(np.mean(evi_pred))\n",
    "\n",
    "    # Store in dictionary\n",
    "    ndvi_evi_results[tile_id] = {\n",
    "        \"predicted_ndvi_next_year\": ndvi_next_year,\n",
    "        \"predicted_evi_next_year\": evi_next_year\n",
    "    }\n",
    "\n",
    "    # Update main results dict\n",
    "    results[tile_id].update(ndvi_evi_results[tile_id])\n",
    "\n",
    "# Print and save\n",
    "print(\"âœ… Added NDVI and EVI forecasts to each tile:\")\n",
    "for t, vals in ndvi_evi_results.items():\n",
    "    print(f\"  {t}: NDVI={vals['predicted_ndvi_next_year']:.3f}, EVI={vals['predicted_evi_next_year']:.3f}\")\n",
    "\n",
    "with open(\"bloom_predictions_per_tile_with_ndvi_evi.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"ğŸ’¾ Saved updated predictions with NDVI and EVI.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa6fc1c-ad30-4a2f-baaf-030be1dafce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
